{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise: Benchmark Different Minimum Segment Sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will discuss the `minimum_segment_size` conversion parameter, and will ask you to experiment with the value, observing how it impacts throughput in optimized models.\n",
    "\n",
    "Additionally, you will perform conversion for 2 additional models, VGG19 and InceptionV3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By the end of this notebook you will be able to:\n",
    "\n",
    "- Conduct experiments to understand the impact of the minimum segment size conversion parameter on a variety of models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.compiler.tensorrt import trt_convert as trt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lab_helpers import (\n",
    "    get_images, batch_input, load_tf_saved_model,\n",
    "    predict_and_benchmark_throughput_from_saved, display_prediction_info\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minimum Segment Size Conversion Parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The success of a TF-TRT optimization task is also dependent on the architecture of the model. The more supporting layers comprising the model, the greater number of TF-TRT layers generated and consequently, higher performance is achieved.\n",
    "\n",
    "The `minimum_segment_size` conversion parameter determines the minimum number of nodes required for a subgraph to be replaced by an optimized TF-TRT op. While its default value of 3 tends to offer the best performance for most models, adjusting this value can have varying impact on different models.\n",
    "\n",
    "For even more on the impacts of this parameter, see the [TF-TRT User Guide](https://docs.nvidia.com/deeplearning/frameworks/tf-trt-user-guide/#min-nodes)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG19 and InceptionV3 Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will utilize 2 additional models: **VGG19** and **InceptionV3**. Execute the following cells to load them, and save them to file, so that they are in the format TF-TRT expects. Feel free to continue reading while the models save."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg19 import VGG19\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg19_model = VGG19(weights='imagenet')\n",
    "inception_v3_model = InceptionV3(weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg19_model.save('vgg19_saved_model')\n",
    "inception_v3_model.save('inception_v3_saved_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch Input for Additional Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we performance inference (and benchmark), we need to batch our input.\n",
    "\n",
    "Our `batch_input` helper function performs model-specific image preprocessing. Therefore we create one set of batched images for each of the 2 additional models. If you're interested, check out `lab_helpers.py` for the source code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_images = 16\n",
    "images = get_images(number_of_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg19_batched_input = batch_input(images, model=\"vgg19\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inception_v3_batched_input = batch_input(images, model=\"inception_v3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark Different Minimum Segment Sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the default value for `minimum_segment_size` is `3`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trt.DEFAULT_TRT_CONVERSION_PARAMS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this exercise you are asked to optimize the  **vgg_19** and **inception_v3** models, varying `minimum_segment_size` to maximize throughput (on FP16 mode only)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Allow for Different Minimum Segment Size Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, `convert_to_trt_graph_and_save` now accepts a `minimum_segment_size` argument, which can be used to control the minimum segment size during conversion to a TF-TRT optimized model. Read the comments to see pertinent changes to our helper function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_trt_graph_and_save(\n",
    "    precision_mode='float16',\n",
    "    input_saved_model_dir='vgg19_saved_model',\n",
    "    max_batch_size=16,\n",
    "    # Allow for control of minimum_segment_size value\n",
    "    minimum_segment_size=3\n",
    "):\n",
    "    precision_mode = trt.TrtPrecisionMode.FP16\n",
    "    converted_save_suffix = '_TFTRT_FP16'\n",
    "    \n",
    "        \n",
    "    if minimum_segment_size != 3:\n",
    "        # Adjust filename for a given minimum segment size\n",
    "        converted_save_suffix += '_MSS_{}'.format(str(minimum_segment_size))\n",
    "        \n",
    "    output_saved_model_dir = input_saved_model_dir + converted_save_suffix\n",
    "    \n",
    "    conversion_params = trt.DEFAULT_TRT_CONVERSION_PARAMS._replace(\n",
    "        precision_mode=precision_mode, \n",
    "        max_workspace_size_bytes=8000000000,\n",
    "        max_batch_size=max_batch_size,\n",
    "        # Pass in adjusted minimum segment size to conversion parameters\n",
    "        minimum_segment_size=minimum_segment_size\n",
    "    )\n",
    "\n",
    "    converter = trt.TrtGraphConverterV2(\n",
    "        input_saved_model_dir=input_saved_model_dir,\n",
    "        conversion_params=conversion_params\n",
    "    )\n",
    "\n",
    "    print('Converting {} to TF-TRT graph precision mode {}...'.format(input_saved_model_dir, precision_mode))\n",
    "    \n",
    "    converter.convert()\n",
    "\n",
    "    print('Saving converted model to {}...'.format(output_saved_model_dir))\n",
    "    converter.save(output_saved_model_dir=output_saved_model_dir)\n",
    "    print('Complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmarking Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you perform the following operations, use this table to track your results."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Throughput\n",
    "\n",
    "      Model  |   Minimum Segment Size\n",
    "             |      1             5      \n",
    "--------------------------------------\n",
    "             |\n",
    "vgg_19       |     TODO          TODO\n",
    "             |\n",
    "             |\n",
    "inception_v3 |     TODO          TODO\n",
    "             |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark Different Minimum Segment Sizes for VGG19"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cells, adjusting `minimum_segment_size` so that you can observe the impact of its value when using VGG19."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_name = 'vgg19'\n",
    "minimum_segment_size = 1 # TODO: Optimize for minimum segment sizes of 1 and 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_saved_model_dir = '{}_saved_model'.format(model_name) # See above for where we saved the model\n",
    "\n",
    "convert_to_trt_graph_and_save(precision_mode='float16',\n",
    "                              minimum_segment_size=minimum_segment_size, # Here we control minimum segment size for the conversion\n",
    "                              input_saved_model_dir=input_saved_model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "infer = load_tf_saved_model('{}_saved_model_TFTRT_FP16_MSS_{}'.format(model_name, str(minimum_segment_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# We use batched input, and process predictions, specifically for VGG19\n",
    "# Record Throughput in the table above\n",
    "all_preds = predict_and_benchmark_throughput_from_saved(vgg19_batched_input, infer, N_run=150, N_warmup_run=50, model='vgg19')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optionally, display prediction info for this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "last_run_preds = all_preds[0]\n",
    "display_prediction_info(last_run_preds, images, model='vgg19')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark Different Minimum Segment Sizes for InceptionV3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cells, adjusting `minimum_segment_size` so that you can observe the impact of its value when using InceptionV3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_name = 'inception_v3'\n",
    "minimum_segment_size = 1 # TODO: Optimize for minimum segment sizes of 1 and 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_saved_model_dir = '{}_saved_model'.format(model_name) # See above for where we saved the model\n",
    "\n",
    "convert_to_trt_graph_and_save(precision_mode='float16',\n",
    "                              minimum_segment_size=minimum_segment_size, # Here we control minimum segment size for the conversion\n",
    "                              input_saved_model_dir=input_saved_model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "infer = load_tf_saved_model('{}_saved_model_TFTRT_FP16_MSS_{}'.format(model_name, str(minimum_segment_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# We use batched input, and process predictions, specifically for InceptionV3\n",
    "# Record Throughput in the table above\n",
    "all_preds = predict_and_benchmark_throughput_from_saved(inception_v3_batched_input, infer, N_run=150, N_warmup_run=50, model='inception_v3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optionally, display prediction info for this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "last_run_preds = all_preds[0]\n",
    "display_prediction_info(last_run_preds, images, model='inception_v3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restart Kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please execute the cell below to restart the kernel and clear GPU memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "IPython.Application.instance().kernel.do_shutdown(True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
